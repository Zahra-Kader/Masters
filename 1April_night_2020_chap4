\chapter{Calibration} % Main chapter title

\label{Chapter4} % For referencing the chapter elsewhere, use \ref{Chapter1} 

%HI intensity mapping with HIRAX presents us with the problem of foreground contamination in our data, which is significantly larger than the HI signal in which we are interested. Foreground removal and high precision calibration are necessary 

In Chapter 3 we presented forecasts of HI-kSZ cross-correlation detections with the HIRAX telescope. In practice, HIRAX first aims to make a direct detection of the weak HI signal which is heavily contaminated by foregrounds. Extracting the HI signal does not only require foreground removal, as discussed in Chapter 3, but also necessitates a well calibrated telescope. Calibration solves for the complex gain factors which feature in the data, thereby allowing us to recover the best estimate of the true sky signal from the measured visibilities.
% as a result of receivers converting antenna voltage to a correlated signal

%Although the HI signal has been detected in cross-correlations, it has not been detected on its own


In this chapter we solve for the gain fluctuations on a feed by feed basis using two different formalisms: Logarithmic redundant calibration (LogCal) and Quasi-redundant correlation calibration (CorrCal). We begin by introducing redundant calibration and discuss the effects of noise and gain scatter on the gain uncertainty using LogCal and thereafter look at the calibratability of different array layouts. 
After assuming perfect baseline redundancy, the effect of a perturbed array is investigated using LogCal. 

We then discuss the CorrCal formalism which is structured to easily include sky information and account for a range of realistic array perturbations. We first present results using the redundant CorrCal case and then assume a quasi-redundant array with known sky information. Thereafter, we compare results obtained CorrCal and LogCal. 


\section {Redundant Baseline Calibration}\label{sec:redundant cal}

We begin by explaining the redundant calibration formalism which has been discussed in \cite{Liu_2010} \cite{Dillon_2016} \cite{Ali_2015}. 
Consider a true sky signal, $x_i$, where $i$ is the antenna index. The signal which we measure with the antennae is then written with dependencies on the complex gain factor, $g_i$, and instrumental noise, $n_i$. 

Thus, we have the equation 

\begin{equation}\label{measured and true signal one antenna}
s_i = g_i x_i + n_i
\end{equation}

Each baseline of an interferometer measures the correlated signals from two respective antennae. This gives the relation between the measured and true visibilities,

\begin{equation}\label{measured vis eqn}
\begin{aligned}
c_{ij} & = \left< s_i s_j \right>\\
& = g^*_i g_j \left< x^*_i x_j \right> + g^*_i \left< x^*_i n_j \right> + g_j \left< x_j n^*_i \right> + \left< n^*_i n_j \right> \\
& = g^*_i g_j y_{i-j} + n_{ij},
\end{aligned}
\end{equation}

where we have combined the last three terms in the second line and set this equal to the noise level which we label as the telescope noise, $n_{ij}$, obtained using the radiometer equation, $T_{sys}/\sqrt{\tau \Delta \nu}$, with system temperature, $T_{sys}$, integration time, $\tau$ and frequency bandwidth, $\Delta \nu$. The correlation of two sky signals gives us the true visibilities, $y_{i-j}$, where the subscript $i-j$ signifies the dependence of the true visibility on the relative difference between two antenna positions. This is because we can assume that redundant baselines observe the same sky. The measured visibilities, $c_{ij}$, will be different for each baseline due to the different noise and complex antenna gains of each antenna. 

We can determine the minimum size array with more known measured correlations than unknown gain and sky parameters. The noise is not a quantity for which we solve, but is instead a systematic effect which we try to minimize. Now, the complex gains are expressed as $g_i = e^{\eta_i + i \phi_i}$ with gain amplitude, $\eta_i$ and a gain phase, $\phi_i$ for a single antenna, if we assume a single feed for each antenna, thus giving $2N$ unknowns. HIRAX contains dual feed polarisation however, we account only for the x polarisation of each antenna. For $N$ dishes we have $N(N-1)/2$ measured visibilities, where we have excluded auto-correlations because they contribute a higher, correlated noise than that of the cross-correlation noise measurements. 

The measured correlations can be used to solve for the gains and sky if we have a sufficient number of unique baselines. This will depend on the number of antennae and their layout. The equation that must be satisfied to have a solvable system is

\begin{equation}\label{array size requirement redundant cal}
N(N-1) > 2N + 2U,
\end{equation}

where $U$ is the number of unique baselines. We are using the real and imaginary components of the $N(N-1)/2$ measured visibilities to solve for both the gain amplitude and phase, as well as both the real and imaginary components of the true visibilities, whose size depends on $U$. 

 For dishes arranged in the north-south and east-west directions, we find that a $2 \times 3$ array is the smallest size that satisfies the condition in equation \ref{array size requirement redundant cal}. This array has $U=7$. The unique baselines are shown on the diagram and are chosen with the assumption that the north-east and south-west baselines do not see the same sky signal, which is true for an asymmetric sky signal. Altogether, 30 knowns are used to solve for 26 unknowns. Using the diagram, we write out one equation for each of the unique baselines as 
 
 \begin{subequations}\label{first:main}
	\begin{equation*}
	c_{1,2} = exp [(\eta_1 + \eta_2) + i(\phi_2 - \phi_1)] y_1 + n_{1,2}
	\end{equation*}
	\begin{equation*}
	c_{1,3} = exp [(\eta_1 + \eta_3) + i(\phi_3 - \phi_1)] y_2 + n_{1,3}
	\end{equation*}
	\begin{equation*}
	c_{1,4} = exp [(\eta_1 + \eta_4) + i(\phi_4 - \phi_1)] y_3 + n_{1,4}
	\end{equation*}
	\begin{equation*}
	c_{1,5} = exp [(\eta_1 + \eta_5) + i(\phi_5 - \phi_1)] y_{\sqrt{10}, NE} + n_{1,5}
	\end{equation*}
	\begin{equation*}
	c_{2,4} = exp [(\eta_2 + \eta_4) + i(\phi_4 - \phi_2)] y_{\sqrt{10},SW} + n_{2,4}
	\end{equation*}
	\begin{equation*}
	c_{1,6} = exp [(\eta_1 + \eta_6) + i(\phi_6 - \phi_1)] y_{\sqrt{13},NE} + n_{1,6}
	\end{equation*}
	\begin{equation}
	c_{3,4} = exp [(\eta_3 + \eta_4) + i(\phi_4 - \phi_3)] y_{\sqrt{13},SW} + n_{3,4} \tag{\ref*{first:main}}.
	\end{equation}
\end{subequations}

The baselines have varying degrees of redundancy, with the $1$ m baseline giving the highest redundancy of 4. 
 
\iffalse
 \begin{subequations}
 \begin{equation*}
c_{1,2} = exp [(\eta_1 + \eta_2) + i(\phi_2 - \phi_1)] y_1 + n_{1,2}
\end{equation*}
 \begin{equation*}
c_{2,3} = exp [(\eta_2 + \eta_3) + i(\phi_3 - \phi_2)] y_1 + n_{2,3}
\end{equation*}
($c_{45}$ and $c_{56}$ the same baseline of 1 with true visibility $y_1$)
 \begin{equation*}
c_{1,3} = exp [(\eta_1 + \eta_3) + i(\phi_3 - \phi_1)] y_2 + n_{1,3}
\end{equation*}
($c_{46}$ has the same baseline of 2 with true visibility $y_2$)
 \begin{equation*}
c_{1,4} = exp [(\eta_1 + \eta_4) + i(\phi_4 - \phi_1)] y_3 + n_{1,4}
\end{equation*}
($c_{25}$ and $c_{36}$ the same baseline of 2 with true visibility $y_3$)
 \begin{equation*}
c_{1,5} = exp [(\eta_1 + \eta_5) + i(\phi_5 - \phi_1)] y_{\sqrt{10}, NE} + n_{1,5}
\end{equation*}
($c_{26}$ has the same NE baseline of ${\sqrt{10}}$  with true visibility $y_{\sqrt{10}, NE}$)
\begin{equation*}
c_{2,4} = exp [(\eta_2 + \eta_4) + i(\phi_4 - \phi_2)] y_{\sqrt{10},SW} + n_{2,4}
\end{equation*}
($c_{35}$ has the same SW baseline of ${\sqrt{10}}$ with true visibility $y_{\sqrt{10}, SW}$)
\begin{equation*}
c_{1,6} = exp [(\eta_1 + \eta_6) + i(\phi_6 - \phi_1)] y_{\sqrt{13},NE} + n_{1,6}
\end{equation*}
\begin{equation*}
c_{3,4} = exp [(\eta_3 + \eta_4) + i(\phi_4 - \phi_3)] y_{\sqrt{13},SW} + n_{3,4}
\end{equation*}
 \end{subequations}
\fi

\subsection {Logarithmic Calibration}\label{section:logcal}

The set of equations in \ref{first:main} can be treated as a linear system if we take the logarithm of each side. We rewrite equation \ref{measured vis eqn} as 

\begin{equation}
c_{ij} = g^*_i g_j y_{i-j} \left( 1 + \frac{n_{ij}}{ g^*_i g_j y_{i-j}} \right), 
\end{equation}

where $ g^*_i g_j = exp[(\eta_i + \eta_j +i(\phi_j - \phi_i))]$

Taking the log of each side then gives

\begin{equation}
In c_{ij} = \eta_i + \eta_j +i(\phi_j - \phi_i) + In y_{i-j} + w_{ij},
\end{equation}

where $w_{ij} = In\left( 1 + \frac{n_{ij}}{ g^*_i g_j y_{i-j}} \right)$. We can then separate the real and imaginary components. 
 The two equations are

\begin{subequations}
\begin{equation}\label{amplitude calibration}
In |c_{ij}| = \eta_i + \eta_j + In |y_{i-j}| + Re w_{i,j}
\end{equation}
\begin{equation}
arg|c_{ij}| = \phi_j - \phi_i + arg |y_{i-j}| + Im w_{i,j}
\end{equation}
\end{subequations}

The amplitude calibration in equation \ref{amplitude calibration}  is written in matrix form as 

\begin{equation}\label{linear lstsq eqn}
\textbf{d} = \textbf{A x} + Re\textbf{w},
\end{equation}

where \textbf{d} represents the known $In |c_{ij}|$, \textbf{A} is the array configuration matrix and \textbf{x} is the matrix of unknowns consisting of the gain amplitude and unique baselines. These matrices are given as follows,

\iffalse

\begin{equation}
\setcounter{MaxMatrixCols}{13}
\begin{pmatrix} In |c_{1,2}|  \\ In |c_{2,3}|\\ In |c_{4,5}|\\In |c_{5,6}|\\In |c_{1,3}|\\
In |c_{4,6}|\\In |c_{1,4}|\\ In |c_{2,5}|\\.\\.\\In |c_{1,6}|\\In |c_{3,4}|
 \end{pmatrix}
=
\begin{pmatrix}
1&1&0&0&0&0&1&0&0&0&0&0&0\\
0&1&1&0&0&0&1&0&0&0&0&0&0\\
0&0&0&1&1&0&1&0&0&0&0&0&0\\
0&0&0&0&1&1&1&0&0&0&0&0&0\\
1&0&1&0&0&0&0&1&0&0&0&0&0\\
0&0&0&1&0&1&0&1&0&0&0&0&0\\
1&0&0&1&0&0&0&0&1&0&0&0&0\\
0&1&0&0&1&0&0&0&1&0&0&0&0\\
&&&.&&&.&&&.\\
&&&.&&&.&&&.\\
1&0&0&0&0&1&0&0&0&0&0&1&0\\
0&0&1&1&0&0&0&0&0&0&0&0&1\\
\end{pmatrix}
\begin{pmatrix}
\eta_1\\\eta_2\\\eta_3\\\eta_4\\\eta_5\\\eta_6\\y_{1}\\y_2\\y_3\\y_{\sqrt{10},NE}\\y_{\sqrt{10},SW}\\y_{\sqrt{13},NE}\\y_{\sqrt{13},SW}
\end{pmatrix}
+
\begin{pmatrix}
Rew_{1,2}\\Rew_{2,3}\\Rew_{4,5}\\Rew_{5,6}\\Rew_{1,3}\\Rew_{4,6}\\Rew_{1,4}\\Rew_{2,5}\\.\\.\\Rew_{1,6}\\Rew_{3,4}
\end{pmatrix}
\end{equation}\\

\fi

\begin{equation}\label{least sq eqn with dAx}
\setcounter{MaxMatrixCols}{13}
\begin{pmatrix} In |c_{1,2}|  \\ In |c_{2,3}|\\ In |c_{4,5}|\\In |c_{5,6}|\\In |c_{1,3}|\\
In |c_{4,6}|\\.\\.\\In |c_{1,6}|\\In |c_{3,4}|
\end{pmatrix}
=
\begin{pmatrix}
1&1&0&0&0&0&1&0&0&0&0&0&0\\
0&1&1&0&0&0&1&0&0&0&0&0&0\\
0&0&0&1&1&0&1&0&0&0&0&0&0\\
0&0&0&0&1&1&1&0&0&0&0&0&0\\
1&0&1&0&0&0&0&1&0&0&0&0&0\\
0&0&0&1&0&1&0&1&0&0&0&0&0\\
&&&.&&&.&&&.\\
&&&.&&&.&&&.\\
1&0&0&0&0&1&0&0&0&0&0&1&0\\
0&0&1&1&0&0&0&0&0&0&0&0&1\\
\end{pmatrix}
\begin{pmatrix}
\eta_1\\.\\.\\\eta_6\\y_{1}\\y_2\\y_3\\y_{\sqrt{10},NE}\\y_{\sqrt{10},SW}\\y_{\sqrt{13},NE}\\y_{\sqrt{13},SW}
\end{pmatrix}
+
\begin{pmatrix}
Rew_{1,2}\\Rew_{2,3}\\Rew_{4,5}\\Rew_{5,6}\\Rew_{1,3}\\Rew_{4,6}\\.\\.\\Rew_{1,4}\\Rew_{3,4}
\end{pmatrix}.
\end{equation}

Note that \textbf{A} would be slightly different for the phase calibration, with the first $1$ in each row changed to a negative $1$. 

This set of equations has no unique solution even in the noiseless case, due to degeneracies which can be understood by considering equation \ref{measured and true signal one antenna}. If we were to multiply the antenna gain by a factor, $\alpha$, and divide the true sky signal by the same factor, the signal measured will remain the same. This degeneracy is broken by constraining the sum of the gain amplitudes. 

The same constraint applies for the phase calibration. However, there are two additional constraints required for phase calibration. If we were to rotate the sky clockwise by a degree, $\phi_{rot}$, and rotate the antennae by the same degree anti-clockwise, the gain phase would remain the same. We thus constrain the product of the phase and antenna position, for both x and y positions. 


The least squares equation is then used to solve for the set of equations, presented here in its familiar form,

\begin{equation}\label{lstsq estimator}
\hat{\textbf{x}} = [\textbf{A}^t \textbf{N}^{-1} \textbf{A}]^{-1}\textbf{A}^t \textbf{N}^{-1}\textbf{d},
\end{equation}
 

where the noise covariance matrix is expressed as $\textbf{N} = \left< Re \textbf{w} Re \textbf{w}^t \right>$ for the amplitude calibration, with the imaginary components taking the same form for the phase calibration. The constraints required to break degeneracies are then added as extra rows in the \textbf{A},\textbf{N} and \textbf{d} matrices. We maintain diagonality of the noise matrix when adding the constraints, and simply set the diagonal values of the additional rows of the matrix to be 1 in order to weight the constraints. 

We first consider amplitude and phase recovery in the noiseless case, using a compact, square $8 \times 8$ array with the dishes placed edge-to-edge. The complex gains are modeled as perturbations about the gain value of 1, so that a complete lack of antennae gain scatter is obtained by setting $\eta, \phi = 0$. In figure \ref{fig:amp_phase_noiseless_8by8} we plot the recovered amplitude versus input amplitude, assuming antennae gain scatter with a Gaussian random distribution on the order of $0.1$. Although this is a large scatter we obtain perfect amplitude recovery in the noiseless case, which shows that the degeneracy is broken. For phase calibration we tested two gain scatter levels of $0.001$ and $0.1$ radians. In this plot we see that the large phases do not give accurate phase recovery even in the absence of noise. This is due to another degeneracy resulting from the additions and subtractions of $2\pi$ that do not alter the gain factor, $g_i$, but do affect the recovered output phase. This is referred to as phase wrapping \cite{Liu_2010} \cite{Li_2018} and as seen in the right panel of figure \ref{fig:amp_phase_noiseless_8by8}, this recovery of antennae with scatter on the order of $0.1$ radians, while the phase recovery is accurate when the small gain scatter of $0.001$ radians is modeled. 


\begin{figure}[h!]
	\centering
	\begin{subfigure}[b]{0.48\linewidth}
		\includegraphics[width=\linewidth]{../corrcal2/noiseless_recgains_vs_simgains_logcal_8by8_pt1gainfluc}
		%\caption{With outliers (70 maps)}
	\end{subfigure}
	\begin{subfigure}[b]{0.48\linewidth}
		\includegraphics[width=\linewidth]{../corrcal2/scatplot_pt1gainfluc_and_pt001gainfluc_phase_noiseless_8by8}
		%\caption{With outliers removed (66 maps)}
	\end{subfigure}
	\caption{(Left) Recovered versus simulated $\eta$ plotted in the noiseless case for an $8\times 8$ array, assuming gain scatter of $0.1$. The plot shows perfect amplitude recovery with all points lying on the green y=x line. (Right) Recovered versus simulated $\phi$ plotted in the noiseless case for an $8\times 8$ array, for both large and small antennae gain scatter on the order of $0.1$ and $0.001$ radians, respectively. %The $0.1$ radian gain scatter is plotted in black with the left and bottom axes, while the $0.001$ radian gain scatter is in blue with top and right axes. 
		From the plot we see that large phases are not accurately recovered due to phase wrapping, while phases close to 0 are unaffected by this.}
	\label{fig:amp_phase_noiseless_8by8}
\end{figure}


\subsubsection{Effect of Array Size and Layout on Gain Error}

The least squares error is computed as the two dimensional matrix,

\begin{equation}\label{least sq eqn}
\mathbf{\Sigma} = [\textbf{A}^t \textbf{N}^{-1} \textbf{A}]^{-1},
\end{equation}

where \textbf{N} is the noise covariance matrix. The errors for each antenna are equal to the square root of the diagonal of $\mathbf{\Sigma}$. 

In order to test only the effect that the number and distribution of dishes has on the gain error, we can take the simplest case and assume that all baselines measure the same sky signal, which is a valid approximation in the presence of a bright point source \cite{Dillon_2016}. We can also assume that all antennae have the same noise level and low gain scatter, thereby reducing the error equation to \cite{Dillon_2016}

\begin{equation}\label{least sq eqn constant noise}
\mathbf{\Sigma} = \frac{1}{\left(S/N\right)^2}[\textbf{A}^t \textbf{A}]^{-1}.
\end{equation}

We explain the derivation of equation \ref{least sq eqn constant noise} in the next section when discussing the weighted noise covariance. For now, we quote the expression and assume a signal-to-noise of 1. This simple expression cannot be evaluated by taking the direct inverse, $[\textbf{A}^t \textbf{A}]^{-1}$, since \textbf{A} is never a square matrix and is therefore not invertible. This is true for any \textbf{A} matrix if we hope to find unique gain solutions. As a result, we must compute the pseudoinverse of $[\textbf{A}^t \textbf{A}]$.

We consider the change in gain error due to an increased number of dishes in figure \ref{fig:lstsq_error_10by10_15by15_16by16} for two different array sizes, viz. $10 \times 10$ and $16 \times 16$. These arrays still maintain a compact square grid, as was used to generate the plots in figure \ref{fig:amp_phase_noiseless_8by8}. The figure shows a discernible pattern in the gain amplitude errors. We can expect the corner dishes to have the highest error and the lowest errors to be situated in a ring around the central dishes. This arrangement is determined by the dishes which contribute to the largest number of baselines. Although it may be expected that the absolute central dishes would be the easiest to calibrate, it is actually the dishes surrounding the centre that are involved in a larger number of baselines \cite{Dillon_2016}. 



%gain errors we would expect if each visibility had the same amplitude and were
%measured with a foreground S/N of 1, Dillon 2016

\begin{figure}[h!]
	\centering
	\begin{subfigure}[b]{0.48\linewidth}
		\includegraphics[width=\linewidth]{../PIPELINE/example_nosims_square/colour_scatterplot_10by10_identity_matrix}
	\end{subfigure}
	\begin{subfigure}[b]{0.48\linewidth}
		\includegraphics[width=\linewidth]{../PIPELINE/example_nosims_square/square_colour_scatterplot_16by16_identity_matrix_amp}
	\end{subfigure}
	\caption{The least squares error is plotted for arrays of size $10 \times 10$ and $16 \times 16$, with the 6 m dishes placed edge-to-edge, using a constant signal-to-noise of 1 for all antennae. The pattern of the errors is due to the baseline redundancies, although the scales on which the errors differ is small within a given array. The number of dishes has a greater impact on gain error.}
	\label{fig:lstsq_error_10by10_15by15_16by16}
\end{figure}


Although the antennae locations do affect gain recovery, the colour scale of the plots show that the errors do not vary much. There is a higher dependence of gain error on the number of antennae in the array. We can expect error to scale as $\Delta \eta \sim 1/\sqrt{N}$ \cite{Liu_2010}. Thus, we expect the gain error for the $10 \times 10$ to be $\sim 0.1$ while the scales of the $16 \times 16$ have lower values of $\sim 0.063$, which is what we obtain. 

Figure \ref{fig:lstsq_error_10by10_15by15_16by16} considers only an increase in dish size while maintaining the same layout. This is because the baseline redundancy was not altered by the addition of more dishes. However, if outlier dishes were added which introduce more unique baselines without increasing their redundancy, the maximum gain error may increase \cite{Dillon_2016}. We now investigate the effect that different array layouts have on calibratability. Further work on array layouts has been undertaken by the HIRAX collaboration and the discussion in this chapter only serves as a test of the antennae gain errors. 

 We present simulations for 4 array designs in figure \ref{fig:nosims4arrayssubfigs} which were considered for HIRAX. There are of course many factors to consider when choosing a design for an interferometer but a detailed discussion on array layouts is out of the scope of this thesis. When comparing the gain errors for the various arrays, we once more assume an identity noise covariance matrix, so that the errors depend only on \textbf{A}. Four layouts are considered as alternatives to the square grid introduced in figure \ref{fig:lstsq_error_10by10_15by15_16by16}. The first is a hex grid which has 16 rows and columns of dishes placed edge-to-edge, just like the $16 \times 16$ square grid and contains 256 dishes in total. However, every second row in the hex is offset by $3$ m so that any given dish has a hexagonal distribution of dishes around it, except for the outer dishes which have a slightly higher error as a result, as seen in the top left panel of figure \ref{fig:nosims4arrayssubfigs}. The alternating grid has 8 rows and columns of blocks, each consisting of 4 dishes placed edge-to-edge, with a distance of 2 m between the edges of the dishes in the separate blocks. The third is a subgrid with 2 rows and columns of blocks, each of which is a compact $8 \times 8$ square grid, with a 3 m separation between the blocks. The last array is a HERA-like grid consisting of three components, viz. two slanted squares and a separate diamond, each containing 81 dishes with 6 m separation between the edges of the dishes in adjacent components. Thus, the total number of dishes is 243. The HERA-like array is therefore the only one which contains fewer than $256$ dishes. The simulated layout plotted here is a modified version of the full 331-dish HERA layout presented in \cite{Dillon_2016} which consists of a different number of dishes in each component of the array. 
 
 \begin{figure}
 	\centering
 	\includegraphics[width=0.9\linewidth]{../PIPELINE/nosims_4arrays_subfigs}
 	\caption{Gain amplitude errors for four array layouts are presented. The top left (hex), bottom left (alternating) and bottom right (subgrid) have 256 dishes while the top right (HERA-like) has 243 dishes. These four can be compared with the 256 dish square grid in the right panel of figure \ref{fig:lstsq_error_10by10_15by15_16by16}. From the plot we can see that the HERA-like layout has the lowest error while the alternating and subgrid have equal scales of gain errors.}
 	\label{fig:nosims4arrayssubfigs}
 \end{figure}
 
 The scales on which the errors differ across the 5 arrays is on the order of $0.002$, assuring us that no particular layout is much less calibratable than any other. However, we can analyze the discrepancies in gain errors and compare these to the baseline redundancy plot in Figure \ref{fig:baselineredundancy5arrays} so as to find the relation between baseline-redundancy and gain error. 



\begin{figure}[h!]
	\centering
	\includegraphics[width=0.7\linewidth]{../corrcal2/Baseline_redundancy_5_arrays}
	\caption{Plot showing the unique baselines and their corresponding redundancies for five different array layouts. We can see that the two subgrids have the exact same baseline-redundancy relation. The square, hex and HERA grids are very similar but the HERA has the highest maximum redundancy of 247 and a 512 unique baselines. The square and hex both have maximum redundancy of 240 but the hex has more unique baselines, which means fewer redundancies per unique baseline.}
	\label{fig:baselineredundancy5arrays}
\end{figure}

The alternating grid and subgrid have the same baseline-redundancy dependence, with 1012 unique baselines and a maximum redundancy of 224. Thus, we obtain the exact same scales of gain errors for these two arrays in figure \ref{fig:nosims4arrayssubfigs}. The subgrids have the most unique baselines from all 5 arrays. However, the reduced redundancy results in the highest maximal gain error, with their least calibratable dishes expecting 2\% higher error than that of the other arrays. With regards to the hex and square grids, we notice that the baseline-redundancy plot is very similar for both. However, the square grid does have slightly fewer unique baselines than the hex, which indicates a higher maximal baseline redundancy. The arrangement of antennae in the square grid is therefore better suited for redundant gain calibration than that of the hex grid. The HERA-like grid has a slightly higher redundancy than the other arrays, and more unique baselines than the square and hex grids. This array has the best baseline-redundancy relation, and as a result has the lowest gain errors despite having the least number of dishes.



\subsubsection{Weighted Noise Covariance Matrix}

For the rest of the chapter, we continue to assume that the HIRAX layout consists of a compact, square grid.

Let us now return to equation \ref{least sq eqn} and examine the noise covariance matrix in more detail, following the calculation in \cite{Liu_2010}. As expressed in section \ref{section:logcal}, \textbf{N} is written as $\textbf{N} = \left< Re \textbf{w} Re \textbf{w}^t \right>$ with $w_{ij} = In\left( 1 + \frac{n_{ij}}{ g^*_i g_j y_{i-j}} \right)$. If we assume a large signal-to-noise, the simplification of $y_{i-j} \gg n_{ij}$ would allow us to write  $w_{ij} \sim \frac{n_{ij}}{ g^*_i g_j y_{i-j}}$. Replacing $c_{ij}$ from equation \ref {measured vis eqn}, we have 

\begin{equation}
w_{ij} \sim \frac{e^{-i\phi}}{|c_{ij}|} (n_r + in_i),
\end{equation}

where we have used $c_{ij} = |c_{ij}| e^{i\phi}$ with $\phi = arg(c_{ij})$, and separated $n_{ij}$ into its real and imaginary components, $n_r$ and $n_i$, respectively. The real component of $w_{ij}$ can then be expressed as

\begin{equation}\label{Re w}
Re (w_\alpha) = \frac{1}{|c_\alpha|} (n_r cos\phi + n_i sin\phi),
\end{equation}

where $\alpha$ is the baseline index which replaces the subscript $ij$ by assigning a value of $\alpha$ to the baselines formed between each pair of antennae. The expression for the noise covariance is then

\begin{equation}
N_{\alpha \alpha} = \frac{1}{|c_\alpha|^2}(\left< n_r n_r \right> cos^2\phi + 2\left<n_r n_i \right> cos\phi sin\phi + \left< n_i n_i\right> sin^2\phi).
\end{equation}

We can assume Gaussian noise with independent real and imaginary components distributed with a standard deviation, $\sigma$, such that $\left<n_r n_r \right> = \sigma^2 = \left<n_i n_i \right>$ and $\left<n_r n_i \right> = 0$. This gives the final, weighted expression for the diagonal matrix,

\begin{equation}\label{weighted noise cov}
N_{\alpha \alpha} = \frac{\sigma^2}{|c_\alpha|^2}.
\end{equation}

where we have set $N_{\alpha \beta} = 0$ under the assumption of uncorrelated noise for different baselines. 

The simplified expression, $\textbf{N} = \frac{1}{S/N}\times \textbf{I}$ which was used in equation \ref{least sq eqn constant noise} now follows easily from equation \ref{weighted noise cov} if equal signal is assumed across all baselines. However, if the sky signal is not constant, the $\frac{1}{|c|^2}$ factor takes into account which baselines are more likely to pick up the signal, thereby returning more accurate gain errors. To understand this, consider a signal whose power is picked up by short baselines. The antennae errors will be weighted such that a lower gain error will be obtained for those dishes that contribute to the largest number of short baselines, i.e. the central dishes. In contrast, a signal picked up by the longest baselines will likewise have a reduced gain error in the outer dishes \cite{Liu_2010}. 

This is demonstrated in figure \ref{fig:8by8positionalscatterwithblstrueviscolorbar}, which depicts the $8 \times 8$ square grid using an annotated scatter plot. Six unique baselines are shown as well with the magnitude of the true visibilities picked up by each baseline. These visibilities have a maximum magnitude of $|y_{i-j}| \sim 2.4$. As shown in the plot, it is the shortest baselines between adjacent dishes in the North-South and East-West directions which observe the highest visibility. The short baselines in the North-West and South-East directions receive a lower signal on the order of $|y_{i-j}| \sim 0.5$. Many of the intermediate length baselines have visibilities on roughly the same order of magnitude. Lastly, the dotted black lines are indicative of all long baselines that have visibilities $|y_{i-j}| \sim 0$. As a result, we expect the gain errors to be weighted such that the central dishes will have a reduced error. This result is shown in figure \ref{fig:lstsq_error_8by8_pt001gainfluc} and discussed thereafter.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.7\linewidth]{../corrcal2/8by8_positional_scatter_with_bls_truevis_colorbar}
	\caption{Annotated scatter plot of the $8 \times 8$ square grid with 6 unique baselines shown. The correlated sky signal that is picked up by 4 of these baselines is indicated by the colour plot. The two black dotted lines represent the longest baselines which pick up zero sky signal.}
	\label{fig:8by8positionalscatterwithblstrueviscolorbar}
\end{figure}

One problem which arises from the weighting in equation \ref{weighted noise cov} is that the estimator in equation \ref{lstsq estimator} is no longer unbiased. As a result, the recovered gains will not converge to the values of the input gains after averaging over many noise realisations. This is because equation \ref{linear lstsq eqn} relies on all quantities on the right hand side being independent of \textbf{d}, in order to use linear least squares fitting. However, substituting equation \ref{Re w} into equation \ref{linear lstsq eqn} introduces nonlinearities. We discuss this further in the next section.


For now, we investigate the effect that telescope noise and gain fluctuations have on the recovered gain errors. The Gaussian noise used in the simulations assumes a channel width of 390 kHz and an integration time of $\tau = 10 s$. Two different system temperatures are assumed when calculating the noise, viz. $T_{sys} = 50$ K and $5$ K and these are plotted for two different gain fluctuations which are on the order of $\eta = 0.001$ and $\eta = 0.1$. 
 

\begin{figure}[h!]
	\centering
	\begin{subfigure}[b]{0.48\linewidth}
		\includegraphics[width=\linewidth]{../corrcal2/8by8_leastsqerr_5K_tsys_fg21cm_pt001gainfluc_1runs}
		%\caption{With outliers (70 maps)}
	\end{subfigure}
	\begin{subfigure}[b]{0.48\linewidth}
		\includegraphics[width=\linewidth]{../corrcal2/8by8_leastsqerr_50K_tsys_fg21cm_pt001gainfluc_1runs}
		%\caption{With outliers removed (66 maps)}
	\end{subfigure}
	\caption{Least squares error plotted for a noisy $8 \times 8$ array with 6 m dishes placed edge to edge. The plots show two separate noise levels, with the left and right plots assuming antenna system temperatures of $T_{sys}=5 K$ and $T_{sys}=50 K$, respectively. The symmetry of the errors is due to the baseline redundancy, although the error differences are small.}
	\label{fig:lstsq_error_8by8_pt001gainfluc}
\end{figure}

Figure \ref{fig:lstsq_error_8by8_pt001gainfluc} shows the effect of noise on amplitude gain errors, assuming a gain amplitude on the order of $0.001$, with the left and right panels assuming $5$ K and $50$ K system temperature, respectively. The error scales show that a 10\% gain uncertainty is expected if we assume very low system temperatures of $5$ K. However, the more realistic temperature of $50$ K results in gain errors on the same order of magnitude as the low gain scatter.

Another observation from the plot is the dependence of the gain error on antenna location. When comparing the error pattern in figure \ref{fig:lstsq_error_5by5} to \ref{fig:lstsq_error_10by10_15by15_16by16}, we find that the centrally located antennae have a reduced gain error due to the weighted noise covariance matrix and the magnitude of the visibilities shown in figure \ref{fig:8by8positionalscatterwithblstrueviscolorbar}. Note that we are not comparing the scales of the errors in figures \ref{fig:lstsq_error_5by5} and \ref{fig:lstsq_error_10by10_15by15_16by16}, since the latter assumed a S/N of 1.

\begin{figure}[h!]
	\centering
	\begin{subfigure}[b]{0.48\linewidth}
		\includegraphics[width=\linewidth]{../corrcal2/8by8_leastsqerr_5K_tsys_fg21cm_pt1gainfluc_100runs}
		%\caption{With outliers (70 maps)}
	\end{subfigure}
	\begin{subfigure}[b]{0.48\linewidth}
		\includegraphics[width=\linewidth]{../corrcal2/8by8_leastsqerr_50K_tsys_fg21cm_pt1gainfluc_100runs}
		%\caption{With outliers removed (66 maps)}
	\end{subfigure}
	\caption{Least squares error plotted for a noisy $8 \times 8$ array with 6 m dishes placed edge to edge. The plots show two separate noise levels, averaged over 10 realisations, with the left and right plots assuming antenna system temperatures of $T_{sys}=5 K$ and $T_{sys}=50 K$, respectively. As seen, the noise makes a significant difference to gain errors. We also notice the symmetry of the errors which is due to the baseline redundancy, although the error differences are small.}
	\label{fig:lstsq_error_5by5}
\end{figure}

 Figure \ref{fig:lstsq_error_5by5} shows the effect of noise on amplitude gain errors, assuming a large gain amplitude on the order of $0.1$, with the left and right panels once again assuming $5$ K and $50$ K system temperature, respectively. The error scales are on the same order of magnitude as that of figure \ref{fig:lstsq_error_8by8_pt001gainfluc}. However, we now have gain uncertainties of 0.1\% and 1\% for $5$ K and $50$ K system temperatures, respectively. The \% gain uncertainty is much lower if we assume gain amplitudes of order 0.1 as opposed to 0.001.
 
Unlike figure \ref{fig:lstsq_error_8by8_pt001gainfluc}, we do not observe a perfectly symmetric pattern in gain errors. This is a result of the larger gain scatter which enters in the noise covariance. While the overall pattern in the error scatter plots is still determined by the baseline redundancy from \textbf{A} and magnitude of true visibilities in \textbf{N}, the gain fluctuations present in \textbf{N} will result in corresponding error fluctuations. Note that both the amplitude and phase scatters enter into the $c_{\alpha}$ factor in \textbf{N}, and that the simulated visibilities contain phase scatters of order $\phi=0.1$. 

%you need pretty low gain scatter to use N=I, because aside from equal noise for all dishes

\subsection {Linear Calibration}

So far we have explored a logarithmic approach in solving for gains. However, this technique is biased and suffers from phase degeneracies. In this section we discuss linear calibration (LinCal) which is an iterative process allowing for more accurate results. The gain and sky solutions from LogCal are typically used as a good first guess for LinCal. Even if biased results are obtained from LogCal, many iterations can be run until the results converge on the best solution. We do not quote results using LinCal in this thesis but discuss its use in overcoming the numerical challenges faced with LogCal. 

Let us return to the last line of equation \ref{measured vis eqn} and write the measured visibilities as deviations from an initial guess, using a Taylor expansion. We then have \cite{Ali_2015}

\begin{equation}\label{cij with perturbations}
c_{ij} = g_i^{0*} g_j^{0} y^0_{i-j} + \Delta g_i^{*} g_j^{0} y^0_{i-j} + g_i^{0*} \Delta g_j y^0_{i-j} + g_i^{0*} g_j^{0} \Delta y_{i-j},\\
\end{equation}

where the superscript 0 is used to denote the initial guesses for the gains and visibilities, and $\Delta$ represents the perturbation about the initial guesses. The true values for the quantities are the sum of the initial guess and the perturbation, so that 



\begin{subequations}\label{variables ito init guess and perturbation}
	\begin{align}
	\begin{split}\label{eqn cij ito init guess and ptbn}
c_{ij} = & c^0_{ij} + \Delta c_{ij}\\
=& e^{\eta_i^0 - i\phi_i^0} e^{\eta_j^0 + i\phi_j^0}y^0_{i-j} + \Delta c_{ij}
	\end{split}\\
	\begin{split}
y_{i-j} = & y^0_{i-j} + \Delta y_{i-j}
	\end{split}\\
	\begin{split}\label{g ito init guess and ptbn}
g_i = & g_i^0 +\Delta g_i\\
=& e^{\eta_i^0 + i\phi_i^0} + e^{\eta_i^0 + i\phi_i^0}[\Delta \eta_i +i\Delta \phi_i].
	\end{split}\\
	\end{align}
\end{subequations}

We can use equations \ref{cij with perturbations} together with equation \ref{eqn cij ito init guess and ptbn} to get the expression for $\Delta c_{ij}$ and thereafter substitute $\Delta g^*_i$ and $\Delta g_j$ using equation \ref{g ito init guess and ptbn}. This gives


\begin{equation}
\Delta c_{ij} \approx e^{\eta_i^0 - i\phi_i^0}e^{\eta_j^0 + i\phi_j^0}[\Delta y_{i-j} + y^0_{i-j}(\Delta \eta_i + \Delta \eta_j -i\Delta \phi_i +i\Delta \phi_j)].
\end{equation}

The least squares estimator is written as the analogue of equation \ref{lstsq estimator}, with the unknowns  $\boldsymbol{x}$ now depending on $\Delta \eta$, $\Delta \phi$ and $\Delta y_{i-j}$, and the known $\Delta c_{ij}$ values contained in the data vector. The estimator is then

\begin{equation}
\hat{\boldsymbol{x}} = (\boldsymbol{B}^T  \boldsymbol{B})^{-1} \boldsymbol{B}^T \boldsymbol{d},
\end{equation}

where matrix $\boldsymbol{B}$ is dependent on both the array layout and the initial guesses. Since the initial guess is set equal to the recovered gains from the previous iteration, $\boldsymbol{B}$ must be re-calculated with each iteration \cite{marthi2013nonlinear}. This is different from the constant $\boldsymbol{A}$ matrix used in LogCal. $\boldsymbol{B}$ is also larger than $\boldsymbol{A}$ because the real and imaginary components of the unknowns are solved for simultaneously in LinCal. This leads to LinCal being more computationally challenging than LogCal.

The problem of phase wrapping which was discussed in the implementation of LogCal, does not apply to LinCal because the $\Delta \phi$ values for which we solve are not exponentiated. Thus, there is no $2\pi$ degeneracy. There is also no bias in the LinCal results because the system of equations is completely linear. 

Although we do not compute results using LinCal, we introduce a different calibration formalism in section \ref{sec:correlation cal} which overcomes the challenges discussed in the use of LogCal and LinCal. 

\subsection {Problems with Redundant Calibration}\label{section:problems with redundant cal}


One of the drawbacks of redundant calibration is that it assumes perfect redundancy and does not account for dish misalignments. To demonstrate the effect that dish offsets could have on the gain errors, we introduce random misplacements in the x and y positions of each antennae, of up to 10 cm. For this, we generate visibilities for a $5 \times 5$ array using equation \ref{visibility eqn}, which we rewrite as a function of the baseline $\textbf{b} = \textbf{r}_i - \textbf{r}_j$ with antennae positions $r$. We also use the relation $\textbf{u} = \textbf{b}/\lambda$ to obtain

\begin{equation}\label{meas vis no noise integral with gains}
x(\boldsymbol{b}) = g^*_i g_j \int d^2 \boldsymbol{\theta}  A(\boldsymbol{\theta}) I(\boldsymbol{\theta}) e^{-2\pi i \frac{\boldsymbol{b}}{\lambda}.\boldsymbol{\theta}}.
\end{equation}

We use simulated gains of unity such that the simulated amplitude and phase scatter are $\eta, \phi = 0$. The quantity, $A(\theta)$ in equation \ref{visibility eqn} describes the combined beams of the two antennae for a particular baseline, and is written as $A(\theta) = A_i(\theta) A_j(\theta)$, with $A_i(\theta) = \frac{e^{-\theta^2}}{\sigma_i}$ for a single Gaussian beam. 

We assume a full width at half maximum (FWHM) of $\frac{\lambda}{D}$ for the dish diamater of $D=6$. In simulating primary beams, Healpix maps are used with $n_{side} =128$ for each side of the map, such that the resolution is given as $12 \times nside^2$. We obtain the angular position of each pixel in the map and use this to compute the separation of each pixel from the zenith. We have simulated equal primary beams for each dish and have assumed that the sky intensity is set to a constant value of 1 for each pixel. As a result, the North-East and South-West facing baselines will have the same visibilities, thereby reducing the number of unique baselines expected for an asymmetric sky, as in section \ref{section:logcal}. 

%The $nside$ is a factor that gives the size of a Healpix map, and which relates to resolution by $npix = 12 \times nside^2$, where $npix$ is the number of pixels. We obtain the angular position of each pixel in the map and use this to obtain the separation of each pixel from the zenith. 

%I am assuming here that the sky value is the same in each pixel of a healpix map . Give noise level and compare unique baselines here to the case where different baselines saw different sky.


Using $50$ K system temperature we compute the mean and standard deviations of the gain amplitude errors for 100 noise realisations. Note that the randomized dish scatter remains the same for each run and that only the noise and corresponding measured visibilities change. When calculating the gain errors using imperfect baseline redundancies, it is assumed that the dishes remain on a perfect grid, such that the visibilities change but the \textbf{A} matrix does not. 

Plotting the results in figure \ref{fig:hist_logcal_dish_sep_compare_no_dish_sep}, we can see that the dish scatter gives a mean and spread in errors which is on the order of $\sim 400$ times larger for the gain errors in the perfectly redundant case. Thus, it is worth investigating a more realistic calibration formalism which accounts for array uncertainties and thereby reduces errors caused by them.



\begin{figure}[h!]
		\centering
\begin{subfigure}[b]{0.48\linewidth}
	\includegraphics[width=\linewidth]{../corrcal2/logcal_5by5_manualvis_dishscatter_vs_nodishscatter}
\end{subfigure}\label{key}
\begin{subfigure}[b]{0.48\linewidth}
	\includegraphics[width=\linewidth]{../corrcal2/logcal_std_5by5_manualvis_dishscatter_vs_nodishscatter}
\end{subfigure}
%\begin{subfigure}[b]{0.48\linewidth}
%	\includegraphics[width=\linewidth]{../corrcal2/no_gain_fluc_sigma_pt001_sky_1_runs_100_dishscat_pt5/mean_logcal_dish_scatter}
%\end{subfigure}
%\begin{subfigure}[b]{0.48\linewidth}
%	\includegraphics[width=\linewidth]{../corrcal2/no_gain_fluc_sigma_pt001_sky_1_runs_100_dishscat_pt5/std_logcal_dish_scatter}
%\end{subfigure}
\caption{The mean (left) and standard deviation (right) of the gain amplitude errors is plotted for a set of 100 noise realisations. The red histograms are plotted for the perfectly redundant case in which dishes are placed exactly $6$ m apart on a square grid. The blue histograms showcase a more realistic scenario in which uncertainties in the dish positions lead to a factor of $\sim 400$ increase in gain errors for a 10 cm position uncertainty.}
\label{fig:hist_logcal_dish_sep_compare_no_dish_sep}
\end{figure}


\section{Quasi-redundant Calibration}

In this section we discuss two formalisms which do not rely on perfectly redundant baselines. The first discusses the work introduced in \cite{Liu_2010} which provides an extension of the formalism used in section \ref{sec:redundant cal}. We do not present results in this section but rather discuss the limitations of the formalism. In section \ref{sec:correlation cal}, we explore the correlation calibration (CorrCal) formalism which was introduced in \cite{sievers2017calibration} and show that it is useful in obtaining better gain solutions in the case of dish scatter. %discuss the flexibility of the corrcal formalism in comparison to the extended redundant cal form 

\subsection{Extended Redundant Calibration Formalism}\label{sec:quasi redundant logcal}

We can return to equation \ref{meas vis no noise integral with gains} and assume small visibility noise such that $c(\boldsymbol{b}) = x(\boldsymbol{b})$. Writing the effective sky signal as $I_{eff}(\boldsymbol{\theta}) = A(\boldsymbol{\theta}) I(\boldsymbol{\theta})$, we can then take the Fourier transform of the sky intensity to obtain


\begin{equation}\label{fourier transform of Ieff}
\tilde{I}\left(\frac{\boldsymbol{b}}{\lambda}\right) = \int d^2 \boldsymbol{\theta} I_{eff}(\boldsymbol{\theta}) e^{-2\pi i \frac{\boldsymbol{b}}{\lambda}.\boldsymbol{\theta}}.
\end{equation}

Substituting equation \ref{fourier transform of Ieff} into equation \ref{meas vis no noise integral with gains} gives

\begin{equation}
c(\boldsymbol{b}) =  g^*_i g_j \tilde{I}\left(\frac{\boldsymbol{b}}{\lambda}\right)
\end{equation}

%We have relied so far on perfectly redundant baselines. In the $8\times 8$ array we had $2016$ baselines with $112$ unique baselines. 
Now, in the redundant case, we had $U$ unique baselines whose points on the $uv$ plane were equal to the $uv$ coordinates of their redundant baselines.
We can now introduce baseline perturbations and define vectors, $\boldsymbol{b}_0^\alpha$, whose positions on the $uv$ plane are \textit{clustered} by the $uv$ points of \textit{nearly} redundant baselines. 
Consider an array with imperfect dish positions as was introduced in section \ref{section:problems with redundant cal}. If we simulate a small amount of dish scatter, this will alter the baselines without changing $U$. As a result, $\boldsymbol{b}_0^\alpha$ will have a range of $\alpha =0...U$. If the dish scatter is high, we can assume a larger number of unique baselines and as a result, a wider range for $\alpha$. We can therefore replace $U$ with the variable $U'$ for the quasi-redundant case.

We introduce baseline perturbations, written as $\Delta \boldsymbol{b}_{ij} = \boldsymbol{b}_{ij} - \boldsymbol{b}_0^\alpha$. Assuming $\Delta \boldsymbol{b}_{ij}$ is small, we can Taylor expand so that up to first order we have

\begin{equation}
\begin{aligned}
\tilde{I}\left(\frac{\boldsymbol{b}_{ij}}{\lambda}\right) \approx & \tilde{I}\left(\frac{\boldsymbol{b}_0^\alpha}{\lambda}\right) + \lambda \frac{d}{db} \tilde{I}\left(\frac{\boldsymbol{b}_{ij}}{\lambda}\right)\Bigr|_{\boldsymbol{b}=\boldsymbol{b}_0^\alpha}. \frac{\boldsymbol{b}_{ij} - \boldsymbol{b}_0^\alpha}{\lambda}\\
=& \tilde{I}\left(\frac{\boldsymbol{b}_0^\alpha}{\lambda}\right) + \nabla_u \tilde{I}\left(\frac{\boldsymbol{b}_{ij}}{\lambda}\right). \frac{\Delta \boldsymbol{b}_{ij}}{\lambda},
\end{aligned}
\end{equation}

where $\nabla_u$ denotes the $uv$ plane gradient. We can then write the measured visibilities as

\begin{equation}\label{cij quasi redundant form}
c_{ij} \approx g_i^* g_j c_0^\alpha \left(1+\boldsymbol{h}_0^\alpha. \frac{\Delta \boldsymbol{b}_{ij}}{\lambda}\right), 
\end{equation}

where $\boldsymbol{h}_0^\alpha = \frac{\nabla \tilde{I}}{\tilde{I}}\Bigr|_{\boldsymbol{b}=\boldsymbol{b}_0^\alpha}$ and $c_0^\alpha = \tilde{I}\left(\frac{\boldsymbol{b}_0^\alpha}{\lambda}\right)$. 

Following the same procedure which was used in section \ref{section:logcal}, we take the logarithm of equation \ref{cij quasi redundant form} which gives 

\begin{equation}
\begin{aligned}
In c_{ij} \approx & (\eta_i + \eta_j) + i(\phi_j - \phi_i) + In c_0^\alpha + In\left(1 + \boldsymbol{h}_0^\alpha. \frac{\Delta \boldsymbol{b}_{ij}}{\lambda}\right)\\
\approx & (\eta_i + \eta_j) + i(\phi_j - \phi_i) + In c_0^\alpha +  \boldsymbol{h}_0^\alpha. \frac{\Delta \boldsymbol{b}_{ij}}{\lambda},
\end{aligned}
\end{equation}

where we have assumed $\boldsymbol{h}_0^\alpha. \frac{\Delta \boldsymbol{b}_{ij}}{\lambda} \ll 1$ in the second line; a condition which is satisfied for widefield instruments if $\Delta \boldsymbol{b}_{ij} \ll \lambda$ \cite{Liu_2010}. 

For these equations, we are solving for $\eta$, $\phi$, $In c_0^\alpha$ and $
\boldsymbol{h}_0^\alpha$, and assume that $\Delta \boldsymbol{b}_{ij}$ is known. The minimum array size required to solve this set of equations must satisfy the condition,

\begin{equation}
N(N+1) > 2N +2(r+s) +4r,
\end{equation}

for an $N$ number of dishes. The unique baselines have been separated into those that have near redundancies, $r$ and those that are completely isolated, $s$, such that $U' = r+s$. This inequality is very similar to that of equation  \ref{array size requirement redundant cal}, with the exception of the $4r$ term which has been added here. This is to account for the $uv$ plane gradients which have both real and imaginary components in both $u$ and $v$ directions in the $uv$ plane. Notice that we only solve for the $uv$ gradients of those baselines which have near redundancies. This is because we have added a constraint which stipulates that the isolated baselines have $\Delta \boldsymbol{b}_{ij}=0$. The extra $4r$ unknowns make the $2\times 3$ array, which was the minimum size array needed to solve the redundant case, too small in the quasi-redundant case. Since we have set the requirement of small $\Delta \boldsymbol{b}_{ij}$, we can assume $U=U'$, which gives a minimum size array of $4\times 4$.%$U=24$ with $s=2$. 

The generalised formalism presented here accounts for baseline perturbations by solving for the $uv$ gradients. However, it is not easy to incorporate into the formalism other possible array perturbations which may result from beam variations or pointing offsets. We now introduce a different formalism developed by \cite{sievers2017calibration} called correlation calibration which is more flexible and can thus correct for a wider variety of array perturbations.

\subsection{Correlation Calibration}\label{sec:correlation cal}

There are two problems which arise from redundant calibration. The first which has been discussed already is the idealistic assumption of complete redundancy. Redundancy does not refer only to the baseline vector, but refers also to the primary beams of the dishes. This has been addressed in part in section \ref{sec:quasi redundant logcal}, but the formalism has its limitations in that perturbations that do not affect $uv$ gradients, cannot be accounted for. Another problem is that the redundant calibration formalism assumes that all possible skies are equally likely. In other words, information which is known about the sky is not used to solve for the sky. Instead, the sky values are solved for straightforwardly after specifying the antennae gains. 

\subsubsection{CorrCal formalism}

Let us now discuss the CorrCal formalism which sets up equations for $\chi^2$ and its gradient, $\nabla \chi^2$. First we can write $\chi^2$ using the redundant calibration formalism. Assuming visibilities contain uncorrelated noise, equation \ref{measured vis eqn} can be written in $\chi^2$ form as

\begin{equation}\label{chi sq}
\begin{aligned}
\chi^2 = &\sum \frac{(c_{ij} - g_i^* g_j y_{i-j})^2}{\sigma^2}\\
\Rightarrow \chi^2 =& (\boldsymbol{d} - \boldsymbol{x})^T \boldsymbol{N}^{-1} (\boldsymbol{d} - \boldsymbol{x})
\end{aligned}
\end{equation}

where $\boldsymbol{d}$ is the measured visibilities, $\boldsymbol{x}$ represents the best fit sky and the noise covariance is $\boldsymbol{N} = \sigma^2 \boldsymbol{I}$.

Now, consider a redundant block of visibilities, obtained from perfectly redundant baselines. We can assume that redundant baselines see the same sky signal so that the true visibilities are equal within the block. Since we do not know the value for the true visibilities, we can obtain a best fit by taking the average of n data points,

\begin{equation}
\bar{d} = \frac{1}{n}\sum_\alpha d_\alpha.
\end{equation}

 To make the simplification of matrix multiplications easier, we define $\mathcal{B} \equiv \boldsymbol{1}^T \boldsymbol{N}^{-1}\boldsymbol{d}=\sigma^{-2}(\sum_{\alpha} d_{\alpha})$ and $\mathcal{Q} \equiv \boldsymbol{1}^T \boldsymbol{N}^{-1} \boldsymbol{1} = n\sigma^{-2}$,  where $ \boldsymbol{1}$ is an $n\times 1$ vector of ones. It is clear from the two expressions that $\bar{d} = \frac{\mathcal{B}}{Q}$, with Hermitian $\mathcal{B}$. Then the best fit sky is $\boldsymbol{x} = \frac{\mathcal{B}}{Q} \boldsymbol{1}$.

The $\chi^2$ in equation \ref{chi sq} becomes

\begin{equation}\label{chi sq redundant case}
\begin{aligned}
\chi^2 = & \left(\boldsymbol{d} - \frac{\mathcal{B}}{Q}\boldsymbol{1}\right)^T \boldsymbol{N}^{-1} \left(\boldsymbol{d} - \frac{\mathcal{B}}{Q}\boldsymbol{1}\right)\\
= & \boldsymbol{d}^T \boldsymbol{N}^{-1} \boldsymbol{d} - \frac{\mathcal{B}^T}{Q} \boldsymbol{1}^T \boldsymbol{N}^{-1} \boldsymbol{d} - \frac{\mathcal{B}}{Q} \boldsymbol{d}^T \boldsymbol{N}^{-1} \boldsymbol{1} + \frac{\mathcal{B}^T}{Q} \boldsymbol{1} \boldsymbol{N}^{-1} \boldsymbol{1} \frac{\mathcal{B}}{Q}\\
= & \boldsymbol{d}^T \boldsymbol{N}^{-1} \boldsymbol{d} - \frac{\mathcal{B}^2}{\mathcal{Q}}.
\end{aligned}
\end{equation}

Now that we have obtained the $\chi^2$ using redundant calibration formalism, let us now discuss CorrCal. The visibility covariance for a redundant block of visibilities is just $\left< y_\alpha^* y_\beta \right> = \gamma^* \gamma$, where $\gamma$ is the sky value. Instead of solving for the sky, as is done in redundant calibration, we include the sky into the noise and use known sky information to construct a covariance matrix. 	
This is the basis of the formalism. Thus, equation \ref{chi sq} changes to $\chi^2 = \boldsymbol{d}^T \boldsymbol{N}^{-1} \boldsymbol{d}$ where the noise covariance is given as the sum of the per visibility noise and the visibility covariance within a redundant block: $\boldsymbol{N} = \boldsymbol{N}_{vis} +(\gamma \boldsymbol{1})^T (\gamma \boldsymbol{1})$, with an identity $\boldsymbol{N}_{vis}$ again.  %We do not weight the visibility noise covariance, as was done in equation, since we instead add the visibility covariance to the noise
This gives the full expression for $\chi^2$,

\begin{equation}\label{chi sq corrcal}
\chi^2 = \boldsymbol{d}^T[\boldsymbol{N} +(\gamma \boldsymbol{1})^T (\gamma \boldsymbol{1})]^{-1} \boldsymbol{d},
\end{equation}

where we have relabeled $\boldsymbol{N}_{vis}$ as $\boldsymbol{N}$. 
We now prove that equation \ref{chi sq corrcal} is equivalent to equation \ref{chi sq redundant case} in the redundant case.

We can evaluate the $\chi^2$ further by considering the Woodbury identity for a Hermitian matrix,

\begin{equation}
(\boldsymbol{A} +  \boldsymbol{b}  \boldsymbol{b}^T)^{-1} = \boldsymbol{A}^{-1} - \boldsymbol{A}^{-1} \boldsymbol{b} [\boldsymbol{I} + \boldsymbol{b}^T \boldsymbol{A}^{-1} \boldsymbol{b}]^{-1} \boldsymbol{b}^T \boldsymbol{A}^{-1}.
\end{equation}

Substituting $\boldsymbol{A} = \boldsymbol{N}, \boldsymbol{b} = \gamma \boldsymbol{1}$, we have

\begin{equation}
\chi^2 = \boldsymbol{d}^T (\boldsymbol{N}^{-1} - \boldsymbol{N}^{-1} \boldsymbol{1}(\gamma^{-2} + \boldsymbol{1}^T \boldsymbol{N}^{-1} \boldsymbol{1})^{-1} \boldsymbol{1}^T \boldsymbol{N}^{-1}) \boldsymbol{d}.
\end{equation}

If we assume an infinite sky variance, which is true under the assumption that all possible skies are equally likely, this gives the limit of $\gamma \rightarrow \infty$. The simplified expression is then

\begin{equation}
\begin{aligned}
\chi^2 = & \boldsymbol{d}^T (\boldsymbol{N}^{-1} - \boldsymbol{N}^{-1} \boldsymbol{1}( \boldsymbol{1}^T \boldsymbol{N}^{-1} \boldsymbol{1})^{-1} \boldsymbol{1}^T \boldsymbol{N}^{-1}) \boldsymbol{d} \\
= &\boldsymbol{d}^T \boldsymbol{N}^{-1} \boldsymbol{d} - \frac{\mathcal{B}^2}{\mathcal{Q}}
\end{aligned}
\end{equation}

where the second equality is obtained by substituting for $\mathcal{B}$ and $\mathcal{Q}$. It is clear that the $\chi^2$ expressions in equations \ref{chi sq} and \ref{chi sq corrcal} are equivalent, such that the CorrCal formalism approaches that of traditional redundant calibration if we assume an infinite sky variance and complete baseline redundancy. 

\subsubsection*{$\chi^2$ Construction and Minimization}

We can now write a generalised form for the $\chi^2$ which does not assume equal true visibilities within a redundant block. Since we are now accounting for array perturbations, we can refer to the blocks as \textit{quasi-redundant} blocks and write the visibility covariance as $\left< y_\alpha^* y_\beta \right>  = C_{\alpha \beta}$ for $\alpha$, $\beta$ within a block, such that the visibility covariance matrix, $\boldsymbol{C}$, is calculated separately for each block. The full covariance matrix, $\boldsymbol{C}^{full}$ would then be a set of diagonal quasi-redundant blocks with zero covariance between visibilities in separate blocks. This is a valid assumption if the blocks are constructed correctly. 
%, an assumption which is necessary for computational efficiency. 

The noise is now written as $\boldsymbol{N} = \boldsymbol{N}_{vis} +\boldsymbol{C}$, which gives the equation for $\chi^2$, written with gain factors as 

\begin{equation}
\chi^2 = \boldsymbol{d}^T (\boldsymbol{N} + \boldsymbol{H}^T \boldsymbol{C} \boldsymbol{H})^{-1} \boldsymbol{d}
\end{equation}

where $ \boldsymbol{H} = \boldsymbol{G}^{-1}$ with $G_{ij}=g_i^*g_j$. We have once more relabeled $\boldsymbol{N}_{vis} = \boldsymbol{N}$. 
We can rewrite the visibility covariance as $\boldsymbol{C} = \boldsymbol{S} \boldsymbol{S}^T +  \boldsymbol{R} \boldsymbol{R}^T$ where $\boldsymbol{S}$ is the source vector and $\boldsymbol{R}$ is the quasi-redundant vector. CorrCal allows for sources to be included if there are very bright point sources which we are observing with known positions. We have set $\boldsymbol{S}=\boldsymbol{0}$ for the remainder of the thesis. The vector $\boldsymbol{R}$ is necessary for computational efficiency. Instead of including entire covariance matrices, we decompose the covariances into their eigenvalues and eigenvectors, so that $\boldsymbol{R} = \lambda^{1/2} \boldsymbol{v}$. If we wish to construct $\boldsymbol{R}$ in the traditional redundant calibration case, we can then use $\boldsymbol{C} = (\gamma \boldsymbol{1})^T (\gamma \boldsymbol{1})$ with  $\gamma \rightarrow \infty$, for all redundant blocks. Then $\boldsymbol{R}$ would consist only of uncorrelated real and imaginary components: $R_r = \gamma[1,0,1,0,...]$ and $R_i = \gamma[0,1,0,1,...]$, with $\gamma$ set to a large value.

%Write requirements for what is input into corrcal code here

The gradient of $\chi^2$ is then taken with respect to antenna gains as

\begin{equation}
\nabla \chi^2 = \boldsymbol{d}^T (\boldsymbol{N} + \boldsymbol{H}^T \boldsymbol{C} \boldsymbol{H})^{-1} (\boldsymbol{H}'^T \boldsymbol{C} \boldsymbol{H}+\boldsymbol{H}^T \boldsymbol{C} \boldsymbol{H}')(\boldsymbol{N} + \boldsymbol{H}^T \boldsymbol{C} \boldsymbol{H})^{-1}\boldsymbol{d}
\end{equation}

\subsubsection{CorrCal Simulations}

The code developed in \cite{sievers2017calibration} can be found on GitHub \footnote{\url{https://github.com/sievers/corrcal2}} and implemented in Python. Several inputs are required for the use of CorrCal:
(i) The visibility data as a single array which is separated according to the quasi-redundant blocks, and thereafter expressed in its real and imaginary components as $[r_1, i_1, r_2, i_2 ..]$, (ii) the diagonal elements of the noise covariance, (iii) the indices which separate the different components into their blocks, (iv) the vector $\boldsymbol{R}$ containing the eigenvalues and eigenvectors of the visibility covariance, (v) the source vector $\boldsymbol{S}$ which we set to zero and (vi) the antennae indices separated according to the different blocks.

In order to use CorrCal to test antennae gain recovery, we must also input simulated gains. The real and imaginary components of the gains, $g$ are $e^\eta cos\phi$ and $e^\eta sin\phi$, respectively. We assume that $\eta, \phi = 0$ so that the simulated gains have real components of 1 and imaginary components of 0. The array is again arranged as $[r_1, i_1, r_2, i_2 ..]$, with the gain recovery solution then returned in the same form. Since the simulated gains are set to unity, the gains have real/imaginary components that represent the amplitude/phase of the gains. 

The $\chi^2$ and $\nabla \chi^2$ returned from the CorrCal code are then used to obtain gain solutions using a conjugate gradient solver provided by Scipy \footnote{\url{https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fmin_cg.html/}}. Another requirement for the use of the solver is an initial guess which provides a necessary starting point, after which the results are iterated over until an optimal solution is found.

In this section we consider simulations for both the redundant and quasi-redundant cases for CorrCal, with the results compared to the LogCal simulations. We have only considered amplitude calibration in this section and leave phase calibration for future work.

\subsubsection*{Redundant CorrCal}

 We consider the traditional redundant calibration case for CorrCal and then compare the results to those obtained with LogCal. We carry out simulations using the same array and visibilities used in \ref{section:logcal}, with $T_{sys} = 50$ K. The mean and standard deviation of the recovered gains are plotted for 100 noise realisations. The initial guess used for CorrCal are the results obtained from the LogCal simulations, with the $\eta$ and $\phi$ values exponentiated to form $g$. We see in figure \ref{fig:Redundant_corrcal_vs_logcal_with_logcalinitguess} that the results are very similar for both CorrCal and LogCal, which is expected. %The fact that Logcal gives biased results, and corrcal is returning the same values means that the bias in logcal doesnt impact the results too much 


\begin{figure}[h!]
	\centering
	\begin{subfigure}[b]{0.48\linewidth}
		\includegraphics[width=\linewidth]{../corrcal2/Hist_logcal_redundant_corrcal_comparison_mean}
	\end{subfigure}
	\begin{subfigure}[b]{0.48\linewidth}		\includegraphics[width=\linewidth]{../corrcal2/Hist_logcal_redundant_corrcal_comparison_std}
	\end{subfigure}
\caption{Histograms showing the mean (left) and standard deviation (right) obtained for 100 noise realisations using redundant CorrCal and LogCal. The LogCal results were set as the initial guess for the redundant CorrCal simulations. The results are very similar for both the mean and standard deviations of the 100 runs.}
\label{fig:Redundant_corrcal_vs_logcal_with_logcalinitguess}
\end{figure}



We also investigate the effect that the initial guess has on the results obtained. We therefore compare the redundant CorrCal results from figure \ref{fig:Redundant_corrcal_vs_logcal_with_logcalinitguess} to the results which we would have obtained had we assumed a $10 \%$ offset in simulated gains as the initial guess. Figure \ref{fig:Redundant_corrcal_vs_logcal_with_2initguess} shows that using LogCal gives a mean/standard deviation using LogCal is shown to be four/two times better. A blue $x$ axis is shown in the top axis of the left panel of figure \ref{fig:Redundant_corrcal_vs_logcal_with_2initguess} which corresponds to the blue histogram, while the scales for the red histogram are set by the bottom $x$ axis. It is worth investigating if an initial guess obtained from LinCal would improve results. We leave this for future work.

\begin{figure}[h!]
	\centering
	\begin{subfigure}[b]{0.43\linewidth}
		\includegraphics[width=\linewidth]{../corrcal2/init_guess_corrcal_comparisons_2}
	\end{subfigure}
	\begin{subfigure}[b]{0.5\linewidth}
		\includegraphics[width=\linewidth]{../corrcal2/Hist_logcal_initguess_and_pt1_initguess_std}
	\end{subfigure}
\caption{Histograms showing the mean (left) and standard deviation (right) obtained for 100 noise realisations using two separate initial guesses for redundant CorrCal. The first uses recovered gains from LogCal as the initial guess,while the second assumes a $10\%$ gain offset from the simulated gains. The mean/standard deviation using LogCal is shown to be four/two times better. The left panel contains a blue $x$ axis which corresponds to the blue histogram, while the scales for the red histogram are set by the bottom $x$ axis.}
\label{fig:Redundant_corrcal_vs_logcal_with_2initguess}
\end{figure}

\subsubsection*{Quasi-redundant CorrCal}

We now test the effects of dish scatter on amplitude gain recovery using CorrCal, and compare the results to those obtained in section \ref{section:problems with redundant cal} with LogCal. We use the same visibilities which were simulated in section \ref{section:problems with redundant cal} for both the cases with and without dish scatter. The dish scatter is small enough such that the indices separating the quasi-redundant blocks remain the same as in the case without dish scatter. 

\begin{figure}[h!]
	\centering
	\begin{subfigure}[b]{0.48\linewidth}
		\includegraphics[width=\linewidth]{../corrcal2/corrcal_mean_5by5_manualvis_dishscatter_vs_nodishscatter_linspace}
	\end{subfigure}
	\begin{subfigure}[b]{0.48\linewidth}
		\includegraphics[width=\linewidth]{../corrcal2/corrcal_std_5by5_manualvis_dishscatter_vs_nodishscatter_linspace}
	\end{subfigure}
%	\begin{subfigure}[b]{0.48\linewidth}
%		\includegraphics[width=\linewidth]{../corrcal2/no_gain_fluc_sigma_pt001_sky_1_runs_100_dishscat_pt5/mean_corrcal_dish_scatter}
%	\end{subfigure}
%	\begin{subfigure}[b]{0.48\linewidth}
%		\includegraphics[width=\linewidth]{../corrcal2/no_gain_fluc_sigma_pt001_sky_1_runs_100_dishscat_pt5/std_corrcal_dish_scatter}
%	\end{subfigure}
	\caption{The mean (left) and standard deviation (right) of the amplitude gain error is plotted for a set of 100 noise realisations using CorrCal. The red histograms are plotted for the perfectly redundant case in which dishes are perfectly placed on a square grid, 6 m apart. The blue histograms showcase the more realistic scenario of uncertainties in the dish position which lead to a factor of $\sim 10$ increase in the mean and spread of the gain errors for a 10 cm position uncertainty.}
	\label{fig:hist_corrcal_dish_sep_compare_no_dish_sep}
\end{figure}

%We have discussed redundant baselines already. If some dish scatter is introduced, the baselines within a block are no longer completely redundant. The data can be arranged to fall within redundant blocks given the noise and uv points of each visibility, so that the blocks depend on the uv tolerance, i.e. how close points have to be to each other on the $uv$ plane so that the corresponding baselines are considered redundant. In this thesis, we have introduced visibility scatter to simulate the effects of dish scatter, with the scatter allowing us to maintain the same redundant blocking that was used in the scatterless case. 

Comparing figures \ref{fig:hist_logcal_dish_sep_compare_no_dish_sep} and \ref{fig:hist_corrcal_dish_sep_compare_no_dish_sep}, it is clear that CorrCal gives much more accurate results for the amplitude gains when positional uncertainties are simulated in a given array. The factor by which the gain errors increase as a result of dish scatter is on the order of $\sim 10$ for CorrCal whereas the errors obtained with LogCal were on the order of $\sim 400$ times higher due to the same level of dish scatter.

%\subsubsection{Future Work}
